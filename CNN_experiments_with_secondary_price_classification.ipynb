{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v11CQIKlu5_c"
   },
   "source": [
    "# CNN for classifying NFTs with secondary sales\n",
    "\n",
    "This model is not trained with the whole dataset to save time and get a feel for building CNN architectures and image loading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfVgKhbASw1t"
   },
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNzv1_pot5lM"
   },
   "source": [
    "Pray to google colab gods for a T4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KKRyxYEwjnyw",
    "outputId": "e78d51b4-ea9e-4442-fa9f-021ad1fb0e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla T4 (UUID: GPU-6b072d41-e658-8754-5ab5-169307f4897a)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0VonmI5_35v",
    "outputId": "c5d06d84-ac8e-4fad-86eb-91150a430f99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWiSocYCBpr2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CB_WE0fmFYxB",
    "outputId": "ae4c0c8f-16e1-4559-fa19-8c28a10b587f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting visualkeras\n",
      "  Downloading visualkeras-0.0.2-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from visualkeras) (7.1.2)\n",
      "Collecting aggdraw>=1.3.11\n",
      "  Downloading aggdraw-1.3.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (989 kB)\n",
      "\u001b[K     |████████████████████████████████| 989 kB 37.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from visualkeras) (1.21.6)\n",
      "Installing collected packages: aggdraw, visualkeras\n",
      "Successfully installed aggdraw-1.3.15 visualkeras-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install visualkeras\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDF6LMCzwuQ-"
   },
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUPI0xJnxDbA"
   },
   "outputs": [],
   "source": [
    "#@title Read data\n",
    "nft_transactions = pd.read_csv('data/Data_API.csv',usecols=['Unique_id_collection','Collection_cleaned','Category'])\n",
    "image_names = pd.read_csv('data/image_names.csv')\n",
    "secondary_sales = pd.read_csv('data/secondary_sale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Mqj38Bra2Lh",
    "outputId": "48569f00-125f-4cc9-8c76-b99a9cdfb8bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Games', 'Art', 'Other', 'Collectible', 'Metaverse', 'Utility'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nft_transactions.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GnJKHrBzDhl"
   },
   "outputs": [],
   "source": [
    "#@title Combine and filter data\n",
    "df_filtered = nft_transactions.copy(deep = True)\n",
    "df_filtered['image_name'] = image_names['image_name']\n",
    "df_filtered.drop_duplicates(subset=['image_name'], inplace=True)\n",
    "batch_numbers = (df_filtered.loc[:,'image_name']//10000).astype(str).str.zfill(3)\n",
    "df_filtered.loc[:,'image_name'] = 'images/batch' + batch_numbers + '/' + df_filtered.loc[:,\"image_name\"].astype(str) + '.png'\n",
    "df_filtered = df_filtered.merge(secondary_sales, on='Unique_id_collection', how='left')\n",
    "df_filtered.drop(df_filtered[df_filtered.Category != 'Games'].index, inplace=True)\n",
    "df_filtered.drop(df_filtered.columns.difference(['image_name','secondary_sale','Collection_cleaned','Category']), axis=1, inplace=True)\n",
    "df_filtered.secondary_sale = df_filtered.secondary_sale.astype(str)\n",
    "df_train = df_filtered.sample(frac=0.8)\n",
    "df_test = df_filtered.loc[df_filtered.index.difference(df_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yvPLZ5dBgnfO"
   },
   "outputs": [],
   "source": [
    "# oversample minority class\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X = df_train.image_name.values\n",
    "y = df_train.secondary_sale.values\n",
    "X_over, y_over = oversample.fit_resample(X.reshape(-1,1), y.reshape(-1,1))\n",
    "df_train = pd.DataFrame(np.hstack((X_over,y_over.reshape(-1,1))), columns=['image_name','secondary_sale']).sample(frac=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVZJ2OIpDKQF"
   },
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKYJ99dhIj4u",
    "outputId": "66798154-5ca5-409d-82a9-00d944a8380c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zip_batch00.zip\n",
      "zip_batch01.zip\n",
      "zip_batch02.zip\n",
      "zip_batch03.zip\n",
      "zip_batch04.zip\n",
      "zip_batch05.zip\n",
      "zip_batch06.zip\n",
      "zip_batch07.zip\n",
      "zip_batch08.zip\n",
      "zip_batch09.zip\n",
      "zip_batch10.zip\n",
      "zip_batch11.zip\n",
      "zip_batch12.zip\n",
      "zip_batch13.zip\n",
      "zip_batch14.zip\n",
      "zip_batch15.zip\n",
      "zip_batch16.zip\n"
     ]
    }
   ],
   "source": [
    "#@title Carry images from drive to local session storage for better read speeds\n",
    "for i in range(0,16+1):\n",
    "  batch_name = f'zip_batch{str(i).zfill(2)}.zip'\n",
    "  print(batch_name)\n",
    "  os.system(f'cp data/images/{batch_name} .')\n",
    "  os.system(f'unzip {batch_name} -d images/')\n",
    "  os.system(f'rm {batch_name}')\n",
    "  os.system('cd images && unzip \"*.zip\"')\n",
    "  os.system('cd images && rm *.zip')\n",
    "!rm -rf images/batch000/drive\n",
    "!rm -rf images/batch{005..024}/transformed\n",
    "!rm -rf images/drive\n",
    "#!cd images && find . -type f | cut -d/ -f2 | sort | uniq -c | awk '{s+=$1} END {print total images downloded: s}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwJQKycaekbc",
    "outputId": "9bf5c9ff-822e-436a-bfc5-6c4dcef119fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 5360 invalid image filename(s) in x_col=\"image_name\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 85224 validated image filenames belonging to 2 classes.\n",
      "Found 21306 validated image filenames belonging to 2 classes.\n",
      "Found 47523 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 2872 invalid image filename(s) in x_col=\"image_name\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "#@title Prepare Dataset generators\n",
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "  rescale=1./255,\n",
    "  validation_split=0.2\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "  rescale=1./255\n",
    ")\n",
    "\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "  dataframe=df_train,\n",
    "  x_col='image_name',\n",
    "  y_col='secondary_sale',\n",
    "  target_size=(28, 28),\n",
    "  color_mode='rgb',\n",
    "  class_mode='binary',\n",
    "  batch_size=64,\n",
    "  shuffle=True,\n",
    "  seed=42,\n",
    "  subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "  dataframe=df_train,\n",
    "  x_col='image_name',\n",
    "  y_col='secondary_sale',\n",
    "  target_size=(28, 28),\n",
    "  color_mode='rgb',\n",
    "  class_mode='binary',\n",
    "  batch_size=64,\n",
    "  shuffle=True,\n",
    "  seed=42,\n",
    "  subset='validation'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "  dataframe=df_test,\n",
    "  x_col='image_name',\n",
    "  y_col='secondary_sale',\n",
    "  target_size=(28, 28),\n",
    "  color_mode='rgb',\n",
    "  class_mode='binary',\n",
    "  batch_size=64,\n",
    "  shuffle=False,\n",
    "  seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "qxzeqQ1MVihY",
    "outputId": "03d4188c-e7c5-4fed-9ace-f347ce727701"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    }
   ],
   "source": [
    "#@title Initialize wandb run\n",
    "import wandb\n",
    "wandb.init(project=\"cnn-secondary-sale-prediction\")\n",
    "wandb.config = {\n",
    "  'architecture': 'CNN-mini',\n",
    "  'accelerator': 'P100',\n",
    "  'batch_size': 64,\n",
    "  'epochs': 15,\n",
    "  'starting_learning_rate': 0.001,\n",
    "  'actiovation':'sigmoid',\n",
    "  'optimizer': 'adam'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZxZSSwBSZtt"
   },
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "555ea1a84a16426e925a4367bfd39990",
      "19c4db5fd6974606995db184092fe137",
      "3922113bf3254ef9b7fd26d7b71bec56",
      "d1320851410241acbe702761cc734aa0",
      "64742707c8684c9890757a8b76dd494a",
      "9dfbd26808ed451ab638430ccc4ed367",
      "322665fc89574184b3fdebeb3aec6306",
      "6fef0568969f47588dd7924c26fb7997"
     ]
    },
    "id": "hIR4ZwAN9QO2",
    "outputId": "5ecd3ac1-9c42-467b-92e7-91f3bbf2d8e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 26, 26, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 11, 11, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1601      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,377\n",
      "Trainable params: 21,185\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      " 515/1332 [==========>...................] - ETA: 3:46 - loss: 0.7854 - f1: 0.6110 - accuracy: 0.5830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332/1332 [==============================] - ETA: 0s - loss: 0.7170 - f1: 0.6332 - accuracy: 0.5997"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20220813_182727-29lk2mmr/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1332/1332 [==============================] - 451s 338ms/step - loss: 0.7170 - f1: 0.6332 - accuracy: 0.5997 - val_loss: 0.6333 - val_f1: 0.6803 - val_accuracy: 0.6462 - lr: 0.0010\n",
      "Epoch 2/15\n",
      " 817/1332 [=================>............] - ETA: 1:48 - loss: 0.6591 - f1: 0.6594 - accuracy: 0.6211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332/1332 [==============================] - ETA: 0s - loss: 0.6581 - f1: 0.6621 - accuracy: 0.6221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20220813_182727-29lk2mmr/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1332/1332 [==============================] - 353s 265ms/step - loss: 0.6581 - f1: 0.6621 - accuracy: 0.6221 - val_loss: 0.6310 - val_f1: 0.7028 - val_accuracy: 0.6470 - lr: 0.0010\n",
      "Epoch 3/15\n",
      " 528/1332 [==========>...................] - ETA: 2:37 - loss: 0.6497 - f1: 0.6684 - accuracy: 0.6280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332/1332 [==============================] - 324s 243ms/step - loss: 0.6486 - f1: 0.6707 - accuracy: 0.6298 - val_loss: 0.6318 - val_f1: 0.6758 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "1332/1332 [==============================] - 325s 244ms/step - loss: 0.6423 - f1: 0.6729 - accuracy: 0.6352 - val_loss: 0.6497 - val_f1: 0.7055 - val_accuracy: 0.6298 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "1332/1332 [==============================] - ETA: 0s - loss: 0.6375 - f1: 0.6768 - accuracy: 0.6387"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20220813_182727-29lk2mmr/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1332/1332 [==============================] - 325s 244ms/step - loss: 0.6375 - f1: 0.6768 - accuracy: 0.6387 - val_loss: 0.6274 - val_f1: 0.6766 - val_accuracy: 0.6533 - lr: 0.0010\n",
      "Epoch 6/15\n",
      " 129/1332 [=>............................] - ETA: 3:51 - loss: 0.6306 - f1: 0.6811 - accuracy: 0.6485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332/1332 [==============================] - 323s 242ms/step - loss: 0.6352 - f1: 0.6804 - accuracy: 0.6428 - val_loss: 0.6321 - val_f1: 0.7075 - val_accuracy: 0.6401 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "1332/1332 [==============================] - ETA: 0s - loss: 0.6325 - f1: 0.6801 - accuracy: 0.6423"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20220813_182727-29lk2mmr/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1332/1332 [==============================] - 325s 244ms/step - loss: 0.6325 - f1: 0.6801 - accuracy: 0.6423 - val_loss: 0.6247 - val_f1: 0.6972 - val_accuracy: 0.6514 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "1043/1332 [======================>.......] - ETA: 55s - loss: 0.6299 - f1: 0.6850 - accuracy: 0.6471"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332/1332 [==============================] - ETA: 0s - loss: 0.6302 - f1: 0.6835 - accuracy: 0.6471"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20220813_182727-29lk2mmr/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1332/1332 [==============================] - 322s 242ms/step - loss: 0.6302 - f1: 0.6835 - accuracy: 0.6471 - val_loss: 0.6233 - val_f1: 0.6789 - val_accuracy: 0.6521 - lr: 9.0484e-04\n",
      "Epoch 9/15\n",
      "  15/1332 [..............................] - ETA: 4:31 - loss: 0.6255 - f1: 0.6994 - accuracy: 0.6427"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332/1332 [==============================] - 319s 240ms/step - loss: 0.6274 - f1: 0.6852 - accuracy: 0.6488 - val_loss: 0.6239 - val_f1: 0.6740 - val_accuracy: 0.6528 - lr: 8.1873e-04\n",
      "Epoch 10/15\n",
      "1332/1332 [==============================] - 317s 238ms/step - loss: 0.6247 - f1: 0.6856 - accuracy: 0.6515 - val_loss: 0.6290 - val_f1: 0.6320 - val_accuracy: 0.6416 - lr: 7.4082e-04\n",
      "Epoch 11/15\n",
      "1332/1332 [==============================] - ETA: 0s - loss: 0.6229 - f1: 0.6888 - accuracy: 0.6544"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20220813_182727-29lk2mmr/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1332/1332 [==============================] - 318s 239ms/step - loss: 0.6229 - f1: 0.6888 - accuracy: 0.6544 - val_loss: 0.6231 - val_f1: 0.6731 - val_accuracy: 0.6539 - lr: 6.7032e-04\n",
      "Epoch 12/15\n",
      " 345/1332 [======>.......................] - ETA: 3:08 - loss: 0.6169 - f1: 0.6870 - accuracy: 0.6549"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332/1332 [==============================] - ETA: 0s - loss: 0.6201 - f1: 0.6888 - accuracy: 0.6550"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20220813_182727-29lk2mmr/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1332/1332 [==============================] - 318s 239ms/step - loss: 0.6201 - f1: 0.6888 - accuracy: 0.6550 - val_loss: 0.6201 - val_f1: 0.6857 - val_accuracy: 0.6574 - lr: 6.0653e-04\n",
      "Epoch 13/15\n",
      " 506/1332 [==========>...................] - ETA: 2:37 - loss: 0.6163 - f1: 0.6933 - accuracy: 0.6606"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332/1332 [==============================] - ETA: 0s - loss: 0.6179 - f1: 0.6896 - accuracy: 0.6572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20220813_182727-29lk2mmr/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1332/1332 [==============================] - 319s 239ms/step - loss: 0.6179 - f1: 0.6896 - accuracy: 0.6572 - val_loss: 0.6195 - val_f1: 0.7041 - val_accuracy: 0.6576 - lr: 5.4881e-04\n",
      "Epoch 14/15\n",
      " 200/1332 [===>..........................] - ETA: 3:35 - loss: 0.6093 - f1: 0.6825 - accuracy: 0.6617"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332/1332 [==============================] - ETA: 0s - loss: 0.6161 - f1: 0.6911 - accuracy: 0.6583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20220813_182727-29lk2mmr/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1332/1332 [==============================] - 318s 239ms/step - loss: 0.6161 - f1: 0.6911 - accuracy: 0.6583 - val_loss: 0.6190 - val_f1: 0.7043 - val_accuracy: 0.6547 - lr: 4.9659e-04\n",
      "Epoch 15/15\n",
      "  56/1332 [>.............................] - ETA: 4:06 - loss: 0.6053 - f1: 0.7169 - accuracy: 0.6708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332/1332 [==============================] - ETA: 0s - loss: 0.6136 - f1: 0.6931 - accuracy: 0.6616"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20220813_182727-29lk2mmr/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1332/1332 [==============================] - 318s 239ms/step - loss: 0.6136 - f1: 0.6931 - accuracy: 0.6616 - val_loss: 0.6166 - val_f1: 0.6952 - val_accuracy: 0.6616 - lr: 4.4933e-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555ea1a84a16426e925a4367bfd39990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='6.908 MB of 6.925 MB uploaded (0.018 MB deduped)\\r'), FloatProgress(value=0.997478…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▄▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>f1</td><td>▁▄▅▆▆▇▆▇▇▇▇████</td></tr><tr><td>learning_rate</td><td>████████▇▅▄▃▃▂▁</td></tr><tr><td>loss</td><td>█▄▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▅▅▅▁▆▃▆▆▆▄▆▇▇▆█</td></tr><tr><td>val_f1</td><td>▅█▅█▅█▇▅▅▁▅▆██▇</td></tr><tr><td>val_loss</td><td>▅▄▄█▃▄▃▂▃▄▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.00284</td></tr><tr><td>accuracy</td><td>0.66161</td></tr><tr><td>best_epoch</td><td>14</td></tr><tr><td>best_val_loss</td><td>0.61659</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>f1</td><td>0.69307</td></tr><tr><td>learning_rate</td><td>0.0005</td></tr><tr><td>loss</td><td>0.61356</td></tr><tr><td>val_accuracy</td><td>0.66155</td></tr><tr><td>val_f1</td><td>0.69521</td></tr><tr><td>val_loss</td><td>0.61659</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lyric-silence-16</strong>: <a href=\"https://wandb.ai/cs401/cnn-secondary-sale-prediction/runs/29lk2mmr\" target=\"_blank\">https://wandb.ai/cs401/cnn-secondary-sale-prediction/runs/29lk2mmr</a><br/>Synced 5 W&B file(s), 542 media file(s), 360 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220813_182727-29lk2mmr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/743 [>.............................] - ETA: 3:08 - loss: 0.4990 - f1: 0.1049 - accuracy: 0.8203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743/743 [==============================] - 223s 300ms/step - loss: 0.6353 - f1: 0.4323 - accuracy: 0.6149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6352639198303223, 0.4323253929615021, 0.6149232983589172]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Build and fit model\n",
    "from PIL import ImageFile\n",
    "import tensorflow.keras as keras\n",
    "from wandb.keras import WandbCallback\n",
    "from keras import backend as K\n",
    "import math\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if wandb.run is None:\n",
    "        raise wandb.Error(\"You must call wandb.init() before WandbCallback()\")\n",
    "    wandb.log({'learning_rate': lr}, commit=False)\n",
    "    if epoch < 7:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "def f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(256,256,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=optimizer,metrics=[f1,'accuracy'])\n",
    "wandb_callback = WandbCallback(\n",
    "    input_type=\"image\",\n",
    "    generator=val_images,\n",
    "    labels=[\"No secondary sale\", \"One or more secondary sale\"],\n",
    "    log_evaluation=True,\n",
    "    validation_steps=5\n",
    ")\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "history = model.fit(train_images,\n",
    "  validation_data=val_images,\n",
    "  verbose = 1,\n",
    "    callbacks=[\n",
    "      wandb_callback,\n",
    "      lr_callback\n",
    "    ], epochs=15\n",
    ")\n",
    "\n",
    "wandb.finish()\n",
    "model.evaluate(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Xsonl9xWulEU"
   },
   "outputs": [],
   "source": [
    "#@title Reset GPU when memory errors happen\n",
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
