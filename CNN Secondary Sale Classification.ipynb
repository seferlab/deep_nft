{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v11CQIKlu5_c"
   },
   "source": [
    "# CNN for classifying NFTs with secondary sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pWiSocYCBpr2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import os.path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDF6LMCzwuQ-"
   },
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jUPI0xJnxDbA"
   },
   "outputs": [],
   "source": [
    "#@title Read data\n",
    "nft_transactions = pd.read_csv('data/Data_API.csv',usecols=['Unique_id_collection','Collection_cleaned','Category'])\n",
    "image_names = pd.read_csv('data/image_names.csv')\n",
    "secondary_sales = pd.read_csv('data/secondary_sale_classification_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Mqj38Bra2Lh",
    "outputId": "48569f00-125f-4cc9-8c76-b99a9cdfb8bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Games', 'Art', 'Other', 'Collectible', 'Metaverse', 'Utility'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nft_transactions.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3GnJKHrBzDhl"
   },
   "outputs": [],
   "source": [
    "category = \"Art\" #Keep only Games category\n",
    "\n",
    "df_filtered = nft_transactions.copy(deep = True)\n",
    "df_filtered['image_name'] = image_names['image_name']\n",
    "df_filtered.drop_duplicates(subset=['image_name'], inplace=True)\n",
    "df_filtered.loc[:,'image_name'] = 'images/' + df_filtered.loc[:,\"image_name\"].astype(str) + '.png'\n",
    "files = [\"images/{0}\".format(fname) for fname in os.listdir(\"images\")]\n",
    "df_filtered = df_filtered[df_filtered[\"image_name\"].isin(files)]\n",
    "\n",
    "df_filtered = df_filtered.merge(secondary_sales, on='Unique_id_collection', how='left', suffixes=('_left', '_right'))\n",
    "df_filtered.drop(df_filtered[df_filtered.Category_left != category].index, inplace=True)\n",
    "df_filtered = df_filtered[(df_filtered[\"secondary_sale\"] == 0.0) | (df_filtered[\"secondary_sale\"] == 1.0)]\n",
    "df_filtered.drop(df_filtered.columns.difference(['image_name_left','secondary_sale','Collection_cleaned_left','Category_left']), axis=1, inplace=True)\n",
    "df_filtered.secondary_sale = df_filtered.secondary_sale.astype(int).astype(str)\n",
    "df_filtered.rename(columns={\"image_name_left\": \"image_name\", \"Collection_cleaned_left\": \"Collection_cleaned\", 'Category_left': 'Category'}, inplace=True)\n",
    "df_train = df_filtered.sample(frac=0.8)\n",
    "df_test = df_filtered.loc[df_filtered.index.difference(df_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yvPLZ5dBgnfO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92011\n",
      "       Collection_cleaned Category         image_name secondary_sale\n",
      "85066        Cryptokittie      Art   images/79536.png              0\n",
      "75791        Cryptokittie      Art   images/70613.png              0\n",
      "64603        Cryptokittie      Art   images/59851.png              0\n",
      "13105        Cryptokittie      Art   images/12275.png              0\n",
      "114148       Cryptokittie      Art  images/107358.png              0\n",
      "86424\n",
      "5587\n",
      "done\n",
      "8642\n",
      "1150\n",
      "4227\n",
      "4415\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n",
    "print(df_train.head(5))\n",
    "\n",
    "df1 = df_train[df_train[\"secondary_sale\"] == '0']\n",
    "df2 = df_train[df_train[\"secondary_sale\"] == '1']\n",
    "print(len(df1))\n",
    "print(len(df2))\n",
    "print(\"done\")\n",
    "#import sys\n",
    "#sys.exit(1)\n",
    "\n",
    "# oversample minority class\n",
    "samplefrac = 0.05\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X = df_train.image_name.values\n",
    "y = df_train.secondary_sale.values\n",
    "X_over, y_over = oversample.fit_resample(X.reshape(-1,1), y.reshape(-1,1))\n",
    "df_train = pd.DataFrame(np.hstack((X_over,y_over.reshape(-1,1))), columns=['image_name','secondary_sale']).sample(frac=samplefrac)\n",
    "\n",
    "print(len(df_train))\n",
    "df_test = df_test.sample(frac=0.05)\n",
    "print(len(df_test))\n",
    "df1 = df_train[df_train[\"secondary_sale\"] == '0']\n",
    "df2 = df_train[df_train[\"secondary_sale\"] == '1']\n",
    "print(len(df1))\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVZJ2OIpDKQF"
   },
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwJQKycaekbc",
    "outputId": "9bf5c9ff-822e-436a-bfc5-6c4dcef119fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6914 validated image filenames belonging to 2 classes.\n",
      "Found 1728 validated image filenames belonging to 2 classes.\n",
      "Found 1150 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "  rescale=1./255,\n",
    "  validation_split=0.2\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "  rescale=1./255\n",
    ")\n",
    "\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "  dataframe=df_train,\n",
    "  x_col='image_name',\n",
    "  y_col='secondary_sale',\n",
    "  target_size=(28, 28),\n",
    "  color_mode='rgb',\n",
    "  class_mode='binary',\n",
    "  batch_size=128,\n",
    "  shuffle=True,\n",
    "  seed=42,\n",
    "  subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "  dataframe=df_train,\n",
    "  x_col='image_name',\n",
    "  y_col='secondary_sale',\n",
    "  target_size=(28, 28),\n",
    "  color_mode='rgb',\n",
    "  class_mode='binary',\n",
    "  batch_size=128,\n",
    "  shuffle=True,\n",
    "  seed=42,\n",
    "  subset='validation'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "  dataframe=df_test,\n",
    "  x_col='image_name',\n",
    "  y_col='secondary_sale',\n",
    "  target_size=(28, 28),\n",
    "  color_mode='rgb',\n",
    "  class_mode='binary',\n",
    "  batch_size=128,\n",
    "  shuffle=False,\n",
    "  seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "qxzeqQ1MVihY",
    "outputId": "03d4188c-e7c5-4fed-9ace-f347ce727701"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wandb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#import wandb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#wandb.init(project=\"cnn-secondary-sale\")\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marchitecture\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN-mini\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccelerator\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP100\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m15\u001b[39m,\n\u001b[1;32m      9\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarting_learning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m     10\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactiovation\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
     ]
    }
   ],
   "source": [
    "#import wandb\n",
    "#wandb.init(project=\"cnn-secondary-sale\")\n",
    "\n",
    "wandb.config = {\n",
    "  'architecture': 'CNN-mini',\n",
    "  'accelerator': 'P100',\n",
    "  'batch_size': 128,\n",
    "  'epochs': 15,\n",
    "  'starting_learning_rate': 0.001,\n",
    "  'activation':'sigmoid',\n",
    "  'optimizer': 'adam'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZxZSSwBSZtt"
   },
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "555ea1a84a16426e925a4367bfd39990",
      "19c4db5fd6974606995db184092fe137",
      "3922113bf3254ef9b7fd26d7b71bec56",
      "d1320851410241acbe702761cc734aa0",
      "64742707c8684c9890757a8b76dd494a",
      "9dfbd26808ed451ab638430ccc4ed367",
      "322665fc89574184b3fdebeb3aec6306",
      "6fef0568969f47588dd7924c26fb7997"
     ]
    },
    "id": "hIR4ZwAN9QO2",
    "outputId": "5ecd3ac1-9c42-467b-92e7-91f3bbf2d8e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 26, 26, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 13, 13, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 11, 11, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 5, 5, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 1601      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21377 (83.50 KB)\n",
      "Trainable params: 21185 (82.75 KB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "109/109 [==============================] - 182s 2s/step - loss: 1.0069 - precision: 0.5196 - recall: 0.5230 - f1: 0.5098 - accuracy: 0.5065 - val_loss: 0.6924 - val_precision: 0.6241 - val_recall: 0.0618 - val_f1: 0.1115 - val_accuracy: 0.5226 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "109/109 [==============================] - 177s 2s/step - loss: 0.8488 - precision: 0.5323 - recall: 0.5337 - f1: 0.5146 - accuracy: 0.5108 - val_loss: 0.6923 - val_precision: 0.4920 - val_recall: 0.6442 - val_f1: 0.5551 - val_accuracy: 0.5017 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "109/109 [==============================] - 309s 3s/step - loss: 0.7865 - precision: 0.5168 - recall: 0.5412 - f1: 0.5102 - accuracy: 0.4993 - val_loss: 0.6918 - val_precision: 0.5071 - val_recall: 0.8783 - val_f1: 0.6399 - val_accuracy: 0.5231 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "109/109 [==============================] - 322s 3s/step - loss: 0.7463 - precision: 0.5293 - recall: 0.5388 - f1: 0.5185 - accuracy: 0.5114 - val_loss: 0.6915 - val_precision: 0.6198 - val_recall: 0.0844 - val_f1: 0.1438 - val_accuracy: 0.5203 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "109/109 [==============================] - 475s 4s/step - loss: 0.7375 - precision: 0.5267 - recall: 0.5362 - f1: 0.5033 - accuracy: 0.5111 - val_loss: 0.6935 - val_precision: 0.5002 - val_recall: 0.8953 - val_f1: 0.6382 - val_accuracy: 0.5098 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "109/109 [==============================] - 944s 9s/step - loss: 0.7203 - precision: 0.5292 - recall: 0.5609 - f1: 0.5212 - accuracy: 0.5214 - val_loss: 0.6916 - val_precision: 0.5438 - val_recall: 0.1240 - val_f1: 0.1998 - val_accuracy: 0.5208 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "109/109 [==============================] - 568s 5s/step - loss: 0.7180 - precision: 0.5394 - recall: 0.5530 - f1: 0.5142 - accuracy: 0.5243 - val_loss: 0.6988 - val_precision: 0.4965 - val_recall: 0.9306 - val_f1: 0.6446 - val_accuracy: 0.5035 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "109/109 [==============================] - 496s 5s/step - loss: 0.7119 - precision: 0.5267 - recall: 0.5597 - f1: 0.5210 - accuracy: 0.5195 - val_loss: 0.7104 - val_precision: 0.4974 - val_recall: 0.9656 - val_f1: 0.6532 - val_accuracy: 0.5058 - lr: 9.0484e-04\n",
      "Epoch 9/15\n",
      "109/109 [==============================] - 179s 2s/step - loss: 0.7052 - precision: 0.5321 - recall: 0.5348 - f1: 0.5106 - accuracy: 0.5191 - val_loss: 0.7266 - val_precision: 0.4911 - val_recall: 0.9978 - val_f1: 0.6556 - val_accuracy: 0.4925 - lr: 8.1873e-04\n",
      "Epoch 10/15\n",
      "109/109 [==============================] - 191s 2s/step - loss: 0.7032 - precision: 0.5447 - recall: 0.6072 - f1: 0.5504 - accuracy: 0.5266 - val_loss: 0.6891 - val_precision: 0.5499 - val_recall: 0.2791 - val_f1: 0.3672 - val_accuracy: 0.5341 - lr: 7.4082e-04\n",
      "Epoch 11/15\n",
      "109/109 [==============================] - 139s 1s/step - loss: 0.7036 - precision: 0.5369 - recall: 0.5280 - f1: 0.5066 - accuracy: 0.5185 - val_loss: 0.6873 - val_precision: 0.5333 - val_recall: 0.6192 - val_f1: 0.5701 - val_accuracy: 0.5480 - lr: 6.7032e-04\n",
      "Epoch 12/15\n",
      "109/109 [==============================] - 204s 2s/step - loss: 0.6979 - precision: 0.5528 - recall: 0.5559 - f1: 0.5323 - accuracy: 0.5321 - val_loss: 0.7194 - val_precision: 0.4913 - val_recall: 0.9945 - val_f1: 0.6548 - val_accuracy: 0.4936 - lr: 6.0653e-04\n",
      "Epoch 13/15\n",
      "109/109 [==============================] - 90s 827ms/step - loss: 0.6939 - precision: 0.5515 - recall: 0.5693 - f1: 0.5345 - accuracy: 0.5376 - val_loss: 0.6901 - val_precision: 0.5129 - val_recall: 0.8559 - val_f1: 0.6398 - val_accuracy: 0.5324 - lr: 5.4881e-04\n",
      "Epoch 14/15\n",
      "109/109 [==============================] - 98s 903ms/step - loss: 0.6923 - precision: 0.5479 - recall: 0.6038 - f1: 0.5626 - accuracy: 0.5327 - val_loss: 0.6912 - val_precision: 0.5121 - val_recall: 0.7111 - val_f1: 0.5926 - val_accuracy: 0.5278 - lr: 4.9659e-04\n",
      "Epoch 15/15\n",
      "109/109 [==============================] - 100s 923ms/step - loss: 0.6919 - precision: 0.5536 - recall: 0.5894 - f1: 0.5515 - accuracy: 0.5324 - val_loss: 0.6865 - val_precision: 0.5340 - val_recall: 0.7528 - val_f1: 0.6212 - val_accuracy: 0.5550 - lr: 4.4933e-04\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.7320 - precision: 0.0552 - recall: 0.6303 - f1: 0.0993 - accuracy: 0.3591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7319831848144531,\n",
       " 0.05523551627993584,\n",
       " 0.6303350925445557,\n",
       " 0.0992950052022934,\n",
       " 0.3591304421424866]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import ImageFile\n",
    "import tensorflow.keras as keras\n",
    "#from wandb.keras import WandbCallback\n",
    "from keras import backend as K\n",
    "import math\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall_keras = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall_keras\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision_keras = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision_keras\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    #if wandb.run is None:\n",
    "    #    raise wandb.Error(\"You must call wandb.init() before WandbCallback()\")\n",
    "    #wandb.log({'learning_rate': lr}, commit=False)\n",
    "    if epoch < 7:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(28,28,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "metrics = [precision, recall, f1, \"accuracy\"]\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=optimizer,metrics=metrics)\n",
    "#wandb_callback = WandbCallback(\n",
    "#    input_type=\"image\",\n",
    "#    generator=val_images,\n",
    "#    labels=[\"No secondary sale\", \"One or more secondary sale\"],\n",
    "#    log_evaluation=True,\n",
    "#    validation_steps=5\n",
    "#)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "history = model.fit(train_images,\n",
    "  validation_data=val_images,\n",
    "  verbose = 1,\n",
    "    callbacks=[\n",
    "      #wandb_callback,\n",
    "      lr_callback\n",
    "    ], epochs=15\n",
    ")\n",
    "\n",
    "#wandb.finish()\n",
    "model.evaluate(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
