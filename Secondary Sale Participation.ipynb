{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vm0syr7rnCAI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-ovu8qOMnC3N"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/secondary_sale_dataset.csv')\n",
    "test_ratio = 0.1\n",
    "use_smote = True\n",
    "use_scaler = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2iAFlBpknGoO",
    "outputId": "deb41e79-e7e3-4a3d-c115-04f798c4a585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games\n",
      "\tTrain count: 1,184,546\n",
      "\tTest count: 131,617\n",
      "Art\n",
      "\tTrain count: 1,009,301\n",
      "\tTest count: 112,145\n",
      "Other\n",
      "\tTrain count: 95,619\n",
      "\tTest count: 10,625\n",
      "Collectible\n",
      "\tTrain count: 948,886\n",
      "\tTest count: 105,432\n",
      "Utility\n",
      "\tTrain count: 3,747\n",
      "\tTest count: 417\n",
      "Metaverse\n",
      "\tTrain count: 30,467\n",
      "\tTest count: 3,386\n",
      "All\n",
      "\tTrain count: 3,272,569\n",
      "\tTest count: 363,619\n"
     ]
    }
   ],
   "source": [
    "def split_categories(df):\n",
    "    categorized_data = {}\n",
    "    for category in df['Category'].unique():\n",
    "        categorized_data[category] = {\n",
    "            'df': df[df['Category'] == category].copy(deep=True)\n",
    "        }\n",
    "    categorized_data['All'] = {\n",
    "        'df' : df.copy(deep=True)\n",
    "    }\n",
    "    \n",
    "    return categorized_data\n",
    "\n",
    "# prepare data\n",
    "categorized_data = split_categories(df)\n",
    "feature_columns = ['0','1','2','3','4','5','6','week_1','centrality_buyer','centrality_seller','p_resale']\n",
    "label_column = 'secondary_sale'\n",
    "for key, item in categorized_data.items():\n",
    "    category_df = item['df']\n",
    "    X = category_df[feature_columns].values\n",
    "    y = category_df[label_column].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=42)\n",
    "    categorized_data[key]['X_train'] = X_train\n",
    "    categorized_data[key]['X_test'] = X_test\n",
    "    categorized_data[key]['y_train'] = y_train\n",
    "    categorized_data[key]['y_test'] = y_test\n",
    "    \n",
    "for key, item in categorized_data.items():\n",
    "    print(f'{key}\\n\\tTrain count: {len(item[\"X_train\"]):,}\\n\\tTest count: {len(item[\"X_test\"]):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oryFEGcTnexb",
    "outputId": "bb8c18bb-e4d7-41a5-ebd4-01bd816ebe44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Games\n",
      "\tAccuracy: 0.6828905080650676\n",
      "\tRecall: 0.5840536309807391\n",
      "\tF1 score: 0.45128380421492714\n",
      "\tPresicion 0.3676971527733145\n",
      "\tconfusion_matrix [[72717 29514]\n",
      " [12223 17163]]\n",
      "Training Art\n",
      "\tAccuracy: 0.7262383521333987\n",
      "\tRecall: 0.7342400315373289\n",
      "\tF1 score: 0.8048909140594716\n",
      "\tPresicion 0.8905858858605462\n",
      "\tconfusion_matrix [[18118  7780]\n",
      " [22921 63326]]\n",
      "Training Other\n",
      "\tAccuracy: 0.6193882352941177\n",
      "\tRecall: 0.6077081899518239\n",
      "\tF1 score: 0.3039586919104991\n",
      "\tPresicion 0.20266238237319256\n",
      "\tconfusion_matrix [[5698 3474]\n",
      " [ 570  883]]\n",
      "Training Collectible\n",
      "\tAccuracy: 0.7298448288944533\n",
      "\tRecall: 0.5328940833692017\n",
      "\tF1 score: 0.5305490086199793\n",
      "\tPresicion 0.5282244830981293\n",
      "\tconfusion_matrix [[60854 14375]\n",
      " [14108 16095]]\n",
      "Training Utility\n",
      "\tAccuracy: 0.6330935251798561\n",
      "\tRecall: 0.6428571428571429\n",
      "\tF1 score: 0.3703703703703703\n",
      "\tPresicion 0.26011560693641617\n",
      "\tconfusion_matrix [[219 128]\n",
      " [ 25  45]]\n",
      "Training Metaverse\n",
      "\tAccuracy: 0.7058476077968104\n",
      "\tRecall: 0.7286401925391095\n",
      "\tF1 score: 0.7086015213575191\n",
      "\tPresicion 0.6896355353075171\n",
      "\tconfusion_matrix [[1179  545]\n",
      " [ 451 1211]]\n",
      "Training All\n",
      "\tAccuracy: 0.7117477359543918\n",
      "\tRecall: 0.6642610416177605\n",
      "\tF1 score: 0.6539535805077751\n",
      "\tPresicion 0.6439611170714262\n",
      "\tconfusion_matrix [[159767  54757]\n",
      " [ 50057  99038]]\n"
     ]
    }
   ],
   "source": [
    "# fit model Adaboost\n",
    "results = pd.DataFrame(columns=['accuracy','recall','f1','precision','confusion_matrix'], index=categorized_data.keys())\n",
    "for category, category_data in categorized_data.items():\n",
    "    X_train = category_data['X_train']\n",
    "    y_train = category_data['y_train']\n",
    "    X_test = category_data['X_test']\n",
    "    y_test = category_data['y_test']\n",
    "    \n",
    "    print(f'Training {category}')\n",
    "    if use_scaler:\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "  \n",
    "    if use_smote:\n",
    "        oversample = SMOTE()\n",
    "        X_train_res, y_train_res = oversample.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        X_train_res, y_train_res = np.array(X_train), np.array(y_train)\n",
    "    \n",
    "    abc = AdaBoostClassifier(n_estimators=50, learning_rate=1)\n",
    "    abc.fit(X_train_res, y_train_res)\n",
    "    y_pred = abc.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results.loc[category,'accuracy'] = accuracy\n",
    "    results.loc[category,'recall'] = recall_score(y_test, y_pred)\n",
    "    results.loc[category,'f1'] = f1_score(y_test,y_pred)\n",
    "    results.loc[category,'precision'] = precision_score(y_test,y_pred)\n",
    "    results.loc[category,'confusion_matrix'] = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\tAccuracy:\" ,accuracy)\n",
    "    print(\"\\tRecall:\", recall_score(y_test, y_pred))\n",
    "    print(\"\\tF1 score:\",f1_score(y_test,y_pred))\n",
    "    print(\"\\tPresicion\", precision_score(y_test,y_pred))\n",
    "    print(\"\\tconfusion_matrix\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pa9H1ije5luL",
    "outputId": "09869abb-d3e4-442f-90e5-ca93ed3da935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Games\n",
      "\tAccuracy: 0.7390306723295623\n",
      "\tRecall: 0.6608589124072688\n",
      "\tF1 score: 0.5306880909438706\n",
      "\tPresicion 0.4433587507419752\n",
      "\tconfusion_matrix [[77849 24382]\n",
      " [ 9966 19420]]\n",
      "Training Art\n",
      "\tAccuracy: 0.810424004636854\n",
      "\tRecall: 0.8265330968033671\n",
      "\tF1 score: 0.8702329215293715\n",
      "\tPresicion 0.918811625958626\n",
      "\tconfusion_matrix [[19599  6299]\n",
      " [14961 71286]]\n",
      "Training Other\n",
      "\tAccuracy: 0.7452235294117647\n",
      "\tRecall: 0.5691672401927047\n",
      "\tF1 score: 0.37927080944737446\n",
      "\tPresicion 0.2843878954607978\n",
      "\tconfusion_matrix [[7091 2081]\n",
      " [ 626  827]]\n",
      "Training Collectible\n",
      "\tAccuracy: 0.7925202974429015\n",
      "\tRecall: 0.6702976525510711\n",
      "\tF1 score: 0.6492423635051712\n",
      "\tPresicion 0.6294695603507244\n",
      "\tconfusion_matrix [[63312 11917]\n",
      " [ 9958 20245]]\n",
      "Training Utility\n",
      "\tAccuracy: 0.7553956834532374\n",
      "\tRecall: 0.34285714285714286\n",
      "\tF1 score: 0.32\n",
      "\tPresicion 0.3\n",
      "\tconfusion_matrix [[291  56]\n",
      " [ 46  24]]\n",
      "Training Metaverse\n",
      "\tAccuracy: 0.7607796810395747\n",
      "\tRecall: 0.7545126353790613\n",
      "\tF1 score: 0.755877034358047\n",
      "\tPresicion 0.7572463768115942\n",
      "\tconfusion_matrix [[1322  402]\n",
      " [ 408 1254]]\n",
      "Training All\n",
      "\tAccuracy: 0.7770826056944219\n",
      "\tRecall: 0.7257050873604078\n",
      "\tF1 score: 0.7274982770503101\n",
      "\tPresicion 0.7293003504987867\n",
      "\tconfusion_matrix [[174363  40161]\n",
      " [ 40896 108199]]\n"
     ]
    }
   ],
   "source": [
    "# fit model xgboost\n",
    "results = pd.DataFrame(columns=['accuracy','recall','f1','precision','confusion_matrix'], index=categorized_data.keys())\n",
    "for category, category_data in categorized_data.items():\n",
    "    X_train = category_data['X_train']\n",
    "    y_train = category_data['y_train']\n",
    "    X_test = category_data['X_test']\n",
    "    y_test = category_data['y_test']\n",
    "    \n",
    "    print(f'Training {category}') \n",
    "    if use_scaler:\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "  \n",
    "    if use_smote:\n",
    "        oversample = SMOTE()\n",
    "        X_train_res, y_train_res = oversample.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        X_train_res, y_train_res = np.array(X_train), np.array(y_train)\n",
    "    \n",
    "    if category == \"Utility\":\n",
    "        model = XGBClassifier(reg_lambda= 0, reg_alpha = 1, max_depth=15, learning_rate= 0.1, colsample_bytree = 1)\n",
    "    elif category == \"Collectible\":\n",
    "        model = XGBClassifier(reg_lambda= 0.1, reg_alpha = 1, max_depth=15, learning_rate= 0.1)\n",
    "    else:\n",
    "        model = XGBClassifier()\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results.loc[category,'accuracy'] = accuracy\n",
    "    results.loc[category,'recall'] = recall_score(y_test, y_pred)\n",
    "    results.loc[category,'f1'] = f1_score(y_test,y_pred)\n",
    "    results.loc[category,'precision'] = precision_score(y_test,y_pred)\n",
    "    results.loc[category,'confusion_matrix'] = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\tAccuracy:\" ,accuracy)\n",
    "    print(\"\\tRecall:\", recall_score(y_test, y_pred))\n",
    "    print(\"\\tF1 score:\",f1_score(y_test,y_pred))\n",
    "    print(\"\\tPresicion\", precision_score(y_test,y_pred))\n",
    "    print(\"\\tconfusion_matrix\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QPJgh2II19vu",
    "outputId": "1b9c4502-a636-4453-99a6-292a44e1f575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Games\n",
      "\tAccuracy: 0.8477932182012962\n",
      "\tRecall: 0.49179881576260803\n",
      "\tF1 score: 0.5906369413736028\n",
      "\tPresicion 0.739194926090737\n",
      "\tconfusion_matrix [[97132  5099]\n",
      " [14934 14452]]\n",
      "Training Art\n",
      "\tAccuracy: 0.8503187837175086\n",
      "\tRecall: 0.9317773371827426\n",
      "\tF1 score: 0.9054373788814277\n",
      "\tPresicion 0.8805456637265107\n",
      "\tconfusion_matrix [[14996 10902]\n",
      " [ 5884 80363]]\n",
      "Training Other\n",
      "\tAccuracy: 0.8881882352941176\n",
      "\tRecall: 0.2505161734342739\n",
      "\tF1 score: 0.37995824634655523\n",
      "\tPresicion 0.7861771058315334\n",
      "\tconfusion_matrix [[9073   99]\n",
      " [1089  364]]\n",
      "Training Collectible\n",
      "\tAccuracy: 0.8189449123605737\n",
      "\tRecall: 0.5550773102009734\n",
      "\tF1 score: 0.6372222961287747\n",
      "\tPresicion 0.7479032833690221\n",
      "\tconfusion_matrix [[69578  5651]\n",
      " [13438 16765]]\n",
      "Training Utility\n",
      "\tAccuracy: 0.841726618705036\n",
      "\tRecall: 0.18571428571428572\n",
      "\tF1 score: 0.28260869565217395\n",
      "\tPresicion 0.5909090909090909\n",
      "\tconfusion_matrix [[338   9]\n",
      " [ 57  13]]\n",
      "Training Metaverse\n",
      "\tAccuracy: 0.7660956881275842\n",
      "\tRecall: 0.7779783393501805\n",
      "\tF1 score: 0.7655417406749556\n",
      "\tPresicion 0.7534965034965035\n",
      "\tconfusion_matrix [[1301  423]\n",
      " [ 369 1293]]\n",
      "Training All\n",
      "\tAccuracy: 0.8227897882123871\n",
      "\tRecall: 0.7520507059257521\n",
      "\tF1 score: 0.7767959513805418\n",
      "\tPresicion 0.8032250207742342\n",
      "\tconfusion_matrix [[187055  27469]\n",
      " [ 36968 112127]]\n"
     ]
    }
   ],
   "source": [
    "# fit model RandomForest\n",
    "results = pd.DataFrame(columns=['accuracy','recall','f1','precision','confusion_matrix'], index=categorized_data.keys())\n",
    "for category, category_data in categorized_data.items():\n",
    "    X_train = category_data['X_train']\n",
    "    y_train = category_data['y_train']\n",
    "    X_test = category_data['X_test']\n",
    "    y_test = category_data['y_test']\n",
    "    print(f'Training {category}')\n",
    "\n",
    "    if use_scaler:\n",
    "       sc = StandardScaler()\n",
    "       X_train = sc.fit_transform(X_train)\n",
    "       X_test = sc.transform(X_test)\n",
    "  \n",
    "    if use_smote:\n",
    "       oversample = SMOTE()\n",
    "       X_train_res, y_train_res = oversample.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "       X_train_res, y_train_res = np.array(X_train), np.array(y_train)\n",
    "    \n",
    "    rf=RandomForestClassifier(n_estimators=100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "        \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results.loc[category,'accuracy'] = accuracy\n",
    "    results.loc[category,'recall'] = recall_score(y_test, y_pred)\n",
    "    results.loc[category,'f1'] = f1_score(y_test,y_pred)\n",
    "    results.loc[category,'precision'] = precision_score(y_test,y_pred)\n",
    "    results.loc[category,'confusion_matrix'] = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\tAccuracy:\", accuracy)\n",
    "    print(\"\\tRecall:\", recall_score(y_test, y_pred))\n",
    "    print(\"\\tF1 score:\", f1_score(y_test,y_pred))\n",
    "    print(\"\\tPresicion\", precision_score(y_test,y_pred))\n",
    "    print(\"\\tconfusion_matrix\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "jammmY7lYe5G",
    "outputId": "959fc41a-4638-4e02-ac86-cbcd57ff5024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Games\n",
      "\tAccuracy: 0.6353434586717521\n",
      "\tRecall: 0.5478118832096917\n",
      "\tF1 score: 0.40149143918893637\n",
      "\tPresicion 0.3168585769117213\n",
      "\tconfusion_matrix [[67524 34707]\n",
      " [13288 16098]]\n",
      "Training Art\n",
      "\tAccuracy: 0.5385527665076464\n",
      "\tRecall: 0.4808515078785349\n",
      "\tF1 score: 0.6158003756691142\n",
      "\tPresicion 0.8560459067828097\n",
      "\tconfusion_matrix [[18924  6974]\n",
      " [44775 41472]]\n",
      "Training Other\n",
      "\tAccuracy: 0.5773176470588235\n",
      "\tRecall: 0.6111493461803166\n",
      "\tF1 score: 0.2833891814265198\n",
      "\tPresicion 0.1844619858745326\n",
      "\tconfusion_matrix [[5246 3926]\n",
      " [ 565  888]]\n",
      "Training Collectible\n",
      "\tAccuracy: 0.6687153805296304\n",
      "\tRecall: 0.49428864682316326\n",
      "\tF1 score: 0.46087117587133025\n",
      "\tPresicion 0.43168608854061247\n",
      "\tconfusion_matrix [[55575 19654]\n",
      " [15274 14929]]\n",
      "Training Utility\n",
      "\tAccuracy: 0.5251798561151079\n",
      "\tRecall: 0.7\n",
      "\tF1 score: 0.33108108108108103\n",
      "\tPresicion 0.2168141592920354\n",
      "\tconfusion_matrix [[170 177]\n",
      " [ 21  49]]\n",
      "Training Metaverse\n",
      "\tAccuracy: 0.642055522740697\n",
      "\tRecall: 0.5282791817087846\n",
      "\tF1 score: 0.5916442048517521\n",
      "\tPresicion 0.6722817764165391\n",
      "\tconfusion_matrix [[1296  428]\n",
      " [ 784  878]]\n",
      "Training All\n",
      "\tAccuracy: 0.644971797403326\n",
      "\tRecall: 0.5889064019584829\n",
      "\tF1 score: 0.5763223619220154\n",
      "\tPresicion 0.5642648741051116\n",
      "\tconfusion_matrix [[146721  67803]\n",
      " [ 61292  87803]]\n"
     ]
    }
   ],
   "source": [
    "# fit model Logistic\n",
    "results = pd.DataFrame(columns=['accuracy','recall','f1','precision','confusion_matrix'], index=categorized_data.keys())\n",
    "for category, category_data in categorized_data.items():\n",
    "    X_train = category_data['X_train']\n",
    "    y_train = category_data['y_train']\n",
    "    X_test = category_data['X_test']\n",
    "    y_test = category_data['y_test']\n",
    "    print(f'Training {category}')\n",
    "    \n",
    "    if use_scaler:\n",
    "       sc = StandardScaler()\n",
    "       X_train = sc.fit_transform(X_train)\n",
    "       X_test = sc.transform(X_test)\n",
    "  \n",
    "    if use_smote:\n",
    "       oversample = SMOTE()\n",
    "       X_train_res, y_train_res = oversample.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "       X_train_res, y_train_res = np.array(X_train), np.array(y_train)\n",
    "    \n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results.loc[category,'accuracy'] = accuracy\n",
    "    results.loc[category,'recall'] = recall_score(y_test, y_pred)\n",
    "    results.loc[category,'f1'] = f1_score(y_test,y_pred)\n",
    "    results.loc[category,'precision'] = precision_score(y_test,y_pred)\n",
    "    results.loc[category,'confusion_matrix'] = confusion_matrix(y_test, y_pred)\n",
    "  \n",
    "    print(\"\\tAccuracy:\" ,accuracy)\n",
    "    print(\"\\tRecall:\", recall_score(y_test, y_pred))\n",
    "    print(\"\\tF1 score:\",f1_score(y_test,y_pred))\n",
    "    print(\"\\tPresicion\", precision_score(y_test,y_pred))\n",
    "    print(\"\\tconfusion_matrix\", confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
